Evaluation Metrics
==================

Evaluating the performance of generative models, especially for complex data like medical images, requires robust quantitative metrics in addition to qualitative visual inspection. This section outlines the key metrics employed to assess the quality, realism, and diversity of the synthetically generated Lung CT images from the CNF-UNet model, based on the `synthetic_image_generator.evaluate` module.

Quantitative Metrics
--------------------

We utilized a combination of established metrics to provide a comprehensive evaluation:

1.  **Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR), and Structural Similarity Index (SSIM)**
    * **Purpose:** These metrics quantify the per-pixel and structural similarity between images.
        * **MSE** measures the average squared difference between pixels. A lower MSE indicates better pixel-wise similarity.
        * **PSNR** measures the ratio between the maximum possible pixel value and the power of distorting noise. A higher PSNR indicates better quality.
        * **SSIM** is a perceptual metric that quantifies image quality degradation based on structural information, luminance, and contrast changes. Values range from -1 to 1, with 1 being perfect similarity.
    * **Implementation in Project:** These metrics are calculated per-image by the `calculate_image_metrics` function within the `evaluate` module. They use `skimage.metrics` on NumPy arrays that are assumed to be normalized to the `[0, 1]` range. For `peak_signal_noise_ratio` and `structural_similarity`, a `data_range` of `1.0` is specified, and `channel_axis=None` for single-channel (grayscale) images. In the `evaluate_model` function, these metrics are computed for a `num_compare` subset of real and generated image pairs and then averaged.
    * **Results:** [Present your average MSE, PSNR, and SSIM scores here, along with interpretations. E.g., "Our model achieved an average MSE of X.XXX, PSNR of Y.YY dB, and SSIM of Z.ZZZ, suggesting a good fidelity at the pixel level on the compared samples."]

2.  **Fr√©chet Inception Distance (FID)**
    * **Purpose:** FID is a more robust and perceptually relevant metric for assessing the quality and diversity of images generated by generative models. It measures the "distance" between the feature distributions of real and generated images, extracted from a pre-trained Inception-v3 network. A lower FID score indicates that the distribution of generated images is closer to the real image distribution, implying both higher quality and better diversity.
    * **Implementation in Project:** FID is calculated using the `torch_fidelity` library within the `evaluate_model` function. Before calculation, both real and generated images (which are initially in `[-1, 1]` pixel range) are processed using a `fid_transform` (which typically denormalizes them to `[0, 255]` and converts them to PIL Image format). These preprocessed images are then temporarily saved to disk in designated `fid_real_images` and `fid_generated_images` directories. `torch_fidelity` then uses these directories as input to compute the FID score, leveraging CUDA if available. The temporary directories are cleaned up after calculation.
    * **Results:** [Present your FID scores here. E.g., "The FID score obtained was X.XX. This low score demonstrates that the generated images capture the overall statistical properties and diversity of the real dataset effectively."]

Qualitative Evaluation
---------------------

Beyond quantitative metrics, visual inspection by human observers is crucial for generative models. This involves manually reviewing a diverse set of generated images to assess:

* **Realism:** Do the images look like actual Lung CT scans?
* **Anatomical Correctness:** Are anatomical structures (e.g., lungs, blood vessels) plausible?
* **Diversity:** Does the model generate a wide variety of distinct images, or does it suffer from mode collapse?
* **Artifacts:** Are there any noticeable artifacts, noise, or blurring?

* **Clinical Relevance:** Do the images maintain clinical relevance, such as showing variations in lung conditions?